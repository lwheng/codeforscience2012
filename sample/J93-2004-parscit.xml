<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Discovering the lexical features of a language.&amp;quot;</title>
<date>1991</date>
<booktitle>In Proceedings, 29th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<location>Berkeley CA.</location>
<contexts>
<context position="45508" citStr="Brill 1991" startWordPosition="7157" endWordPosition="7158">duce the error rate of the final version of the corpus to approximately 1%. All the skeletally parsed materials have been corrected once, except for the Brown materials, which have been quickly proofread an additional time for gross parsing errors. 5.2 Future Directions A large number of research efforts, both at the University of Pennsylvania and elsewhere, have relied on the output of the Penn Treebank Project to date. A few examples already in print: a number of projects investigating stochastic parsing have used either the POS-tagged materials (Magerman and Marcus 1990; Brill et al. 1990; Brill 1991) or the skeletally parsed corpus (Weischedel et al. 1991; Pereira and Schabes 1992). The POS-tagged corpus has also been used to train a number of different POS taggers including Meteer, Schwartz, and Weischedel (1991), and the skeletally parsed corpus has been used in connection with the development of new methods to exploit intonational cues in disambiguating the parsing of spoken sentences (Veilleux and Ostendorf 1992). The Penn Treebank has been used to bootstrap the development of lexicons for particular applications (Robert Ingria, personal communication) and is being used as a source of</context>
</contexts>
<marker>Brill, 1991</marker>
<rawString>Brill, Eric (1991). &amp;quot;Discovering the lexical features of a language.&amp;quot; In Proceedings, 29th Annual Meeting of the Association for Computational Linguistics. Berkeley CA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Eric Brill</author>
</authors>
<publisher>Magerman, David; Marcus,</publisher>
<marker>Brill, </marker>
<rawString>Brill, Eric; Magerman, David; Marcus,</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Mitchell</author>
<author>Beatrice Santorini</author>
</authors>
<title>Deducing linguistic structure from the statistics of large corpora.&amp;quot;</title>
<date>1990</date>
<booktitle>In Proceedings, DARPA Speech and Natural Language Workshop.</booktitle>
<marker>Mitchell, Santorini, 1990</marker>
<rawString>Mitchell P.; and Santorini, Beatrice (1990). &amp;quot;Deducing linguistic structure from the statistics of large corpora.&amp;quot; In Proceedings, DARPA Speech and Natural Language Workshop. June 1990,275-282.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
</authors>
<title>Memory limitations in natural language processing. Master&apos;s dissertation,</title>
<date>1980</date>
<institution>Massachusetts Institute of Technology,</institution>
<location>Cambridge MA.</location>
<contexts>
<context position="42057" citStr="Church 1980" startWordPosition="6629" endWordPosition="6630">ls listed in Table 4 are available on CD-ROM to members of the Linguistic Data Consortium.&apos; About 3 million words of POS-tagged material and a small sampling of skeletally parsed text are available as part of the first Association for Computational Linguistics/Data Collection Initiative CD-ROM, and a somewhat larger subset of materials is available on cartridge tape directly from the Penn Treebank Project. For information, contact the first author of this paper or send e-mail to treebank@unagi.cis.upenn.edu. 11 This use of pseudo-attachment is identical to its original use in Church&apos;s parser (Church 1980). 12 Contact the Linguistic Data Consortium, 441 Williams Hall, University of Pennsylvania, Philadelphia PA 19104-6305, or send e-mail to ldc@unagi.cis.upenn.edu for more information. 326 Mitchell P. Marcus et al. Building a Large Annotated Corpus of English Table 4 Penn Treebank (as of 11/92). Description Tagged for Skeletal Part-of-Speech Parsing (Tokens) (Tokens) Dept. of Energy abstracts 231,404 231,404 Dow Jones Newswire stories 3,065,776 1,061,166 Dept. of Agriculture bulletins 78,555 78,555 Library of America texts 105,652 105,652 MUC-3 messages 111,828 111,828 IBM Manual sentences 89,1</context>
</contexts>
<marker>Church, 1980</marker>
<rawString>Church, Kenneth W. (1980). Memory limitations in natural language processing. Master&apos;s dissertation, Massachusetts Institute of Technology, Cambridge MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
</authors>
<title>A stochastic parts program and noun phrase parser for unrestricted text.&amp;quot;</title>
<date>1988</date>
<booktitle>In Proceedings, Second Conference on Applied Natural Language Processing.</booktitle>
<pages>136--143</pages>
<contexts>
<context position="15332" citStr="Church 1988" startWordPosition="2431" endWordPosition="2432">tuation 16. PDT Predeterminer 40. Comma 17. POS Possessive ending 41. Colon, semi-colon 18. PRP Personal pronoun 42. Left bracket character 19. PP$ Possessive pronoun 43. Right bracket character 20. RB Adverb 44. Straight double quote 21. RBR Adverb, comparative 45. Left open single quote 22. RBS Adverb, superlative 46. Left open double quote 23. RP Particle 47. Right close single quote 24. SYM Symbol (mathematical or scientific) 48. Right close double quote 2.3.1 Automated Stage. During the early stages of the Penn Treebank project, the initial automatic POS assignment was provided by PARTS (Church 1988), a stochastic algorithm developed at AT&amp;T Bell Labs. PARTS uses a modified version of the Brown Corpus tagset close to our own and assigns POS tags with an error rate of 3-5%. The output of PARTS was automatically tokenized&apos; and the tags assigned by PARTS were automatically mapped onto the Penn Treebank tagset. This mapping introduces about 4% error, since the Penn Treebank tagset makes certain distinctions that the PARTS tagset does not.&apos; A sample of the resulting tagged text, which has an error rate of 7-9%, is shown in Figure 1. More recently, the automatic POS assignment is provided by a </context>
</contexts>
<marker>Church, 1988</marker>
<rawString>Church, Kenneth W. (1988). &amp;quot;A stochastic parts program and noun phrase parser for unrestricted text.&amp;quot; In Proceedings, Second Conference on Applied Natural Language Processing. 136-143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Nelson Francis</author>
</authors>
<title>A standard sample of present-day English for use with digital computers.&amp;quot;</title>
<date>1964</date>
<booktitle>Report to the U.S Office of Education on Cooperative Research Project No. E-007.</booktitle>
<institution>Brown University, Providence RI.</institution>
<contexts>
<context position="4013" citStr="Francis 1964" startWordPosition="596" endWordPosition="597"> able to correct bracketed structures, a task that—not surprisingly—is considerably more difficult than correcting POS-tagged text. Finally, Section 5 describes the composition and size of the current Treebank corpus, briefly reviews some of the research projects that have relied on it to date, and indicates the directions that the project is likely to take in the future. 2. Part-of-Speech Tagging 2.1 A Simplified POS Tagset for English The POS tagsets used to annotate large corpora in the past have traditionally been fairly extensive. The pioneering Brown Corpus distinguishes 87 simple tags (Francis 1964; Francis and Kuera 1982) and allows the formation of compound tags; thus, the contraction I&apos;m is tagged as PPSS+BEM (PPSS for &amp;quot;non-third person nominative personal pronoun&amp;quot; and BEM for &amp;quot;am, &apos;m&amp;quot;.2 Subsequent projects have tended to elaborate the Brown Corpus tagset. For instance, the Lancaster-Oslo/Bergen (LOB) Corpus uses about 135 tags, the Lancaster UCREL group about 165 tags, and the London-Lund Corpus of Spoken English 197 tags.3 The rationale behind developing such large, richly articulated tagsets is to approach &amp;quot;the ideal of providing distinct codings for all classes of words having di</context>
<context position="43973" citStr="Francis 1964" startWordPosition="6912" endWordPosition="6913">nly book chapters, from a variety of American authors including Mark Twain, Henry Adams, Willa Cather, Herman Melville, W. E. 13. Dubois, and Ralph Waldo Emerson. • The MUC-3 texts are all news stories from the Federal News Service about terrorist activities in South America. Some of these texts are translations of Spanish news stories or transcripts of radio broadcasts. They are taken from training materials for the Third Message Understanding Conference. • The Brown Corpus materials were completely retagged by the Penn Treebank project starting from the untagged version of the Brown Corpus (Francis 1964). • The IBM sentences are taken from IBM computer manuals; they are chosen to contain a vocabulary of 3,000 words, and are limited in length. • The ATIS sentences are transcribed versions of spontaneous sentences collected as training materials for the DARPA Air Travel Information System project. The entire corpus has been tagged for POS information, at an estimated error rate 327 Computational Linguistics Volume 19, Number 2 of approximately 3%. The POS-tagged version of the Library of America texts and the Department of Agriculture bulletins have been corrected twice (each by a different ann</context>
</contexts>
<marker>Francis, 1964</marker>
<rawString>Francis, W. Nelson (1964). &amp;quot;A standard sample of present-day English for use with digital computers.&amp;quot; Report to the U.S Office of Education on Cooperative Research Project No. E-007. Brown University, Providence RI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Nelson Francis</author>
<author>Henry Kuera</author>
</authors>
<title>Frequency Analysis of English Usage: Lexicon and Grammar.</title>
<date>1982</date>
<publisher>Houghton Mifflin.</publisher>
<contexts>
<context position="4038" citStr="Francis and Kuera 1982" startWordPosition="598" endWordPosition="601">ct bracketed structures, a task that—not surprisingly—is considerably more difficult than correcting POS-tagged text. Finally, Section 5 describes the composition and size of the current Treebank corpus, briefly reviews some of the research projects that have relied on it to date, and indicates the directions that the project is likely to take in the future. 2. Part-of-Speech Tagging 2.1 A Simplified POS Tagset for English The POS tagsets used to annotate large corpora in the past have traditionally been fairly extensive. The pioneering Brown Corpus distinguishes 87 simple tags (Francis 1964; Francis and Kuera 1982) and allows the formation of compound tags; thus, the contraction I&apos;m is tagged as PPSS+BEM (PPSS for &amp;quot;non-third person nominative personal pronoun&amp;quot; and BEM for &amp;quot;am, &apos;m&amp;quot;.2 Subsequent projects have tended to elaborate the Brown Corpus tagset. For instance, the Lancaster-Oslo/Bergen (LOB) Corpus uses about 135 tags, the Lancaster UCREL group about 165 tags, and the London-Lund Corpus of Spoken English 197 tags.3 The rationale behind developing such large, richly articulated tagsets is to approach &amp;quot;the ideal of providing distinct codings for all classes of words having distinct grammatical behavi</context>
</contexts>
<marker>Francis, Kuera, 1982</marker>
<rawString>Francis, W. Nelson, and Kuera, Henry (1982). Frequency Analysis of English Usage: Lexicon and Grammar. Houghton Mifflin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Garside</author>
<author>Geoffrey Leech</author>
<author>Geoffrey Sampson</author>
</authors>
<title>The Computational Analysis of English: A Corpus-Based Approach.</title>
<date>1987</date>
<publisher>Longman.</publisher>
<marker>Garside, Leech, Sampson, 1987</marker>
<rawString>Garside, Roger; Leech, Geoffrey; and Sampson, Geoffrey (1987). The Computational Analysis of English: A Corpus-Based Approach. Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
</authors>
<title>User manual for Fidditch.&amp;quot;</title>
<date>1983</date>
<tech>Technical memorandum 7590-142,</tech>
<institution>Naval Research Laboratory.</institution>
<contexts>
<context position="24186" citStr="Hindle 1983" startWordPosition="3797" endWordPosition="3798">on. The mean disagreement rate between PARTS and the benchmark version was 319 Computational Linguistics Volume 19, Number 2 9.6%, while the corrected version had a mean disagreement rate of 5.4%, as noted above.&apos; The annotators were thus reducing the error rate by about 4.2%. 4. Bracketing 4.1 Basic Methodology The methodology for bracketing the corpus is completely parallel to that for tagging— hand correction of the output of an errorful automatic process. Fidditch, a deterministic parser developed by Donald Hindle first at the University of Pennsylvania and subsequently at AT&amp;T Bell Labs (Hindle 1983, 1989), is used to provide an initial parse of the material. Annotators then hand correct the parser&apos;s output using a mouse-based interface implemented in GNU Emacs Lisp. Fidditch has three properties that make it ideally suited to serve as a preprocessor to hand correction: • Fidditch always provides exactly one analysis for any given sentence, so that annotators need not search through multiple analyses. • Fidditch never attaches any constituent whose role in the larger structure it cannot determine with certainty. In cases of uncertainty, Fidditch chunks the input into a string of trees, p</context>
</contexts>
<marker>Hindle, 1983</marker>
<rawString>Hindle, Donald (1983). &amp;quot;User manual for Fidditch.&amp;quot; Technical memorandum 7590-142, Naval Research Laboratory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
</authors>
<title>Acquiring disambiguation rules from text.&amp;quot;</title>
<date>1989</date>
<booktitle>In Proceedings, 27th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<marker>Hindle, 1989</marker>
<rawString>Hindle, Donald (1989). &amp;quot;Acquiring disambiguation rules from text.&amp;quot; In Proceedings, 27th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bil Lewis</author>
<author>LaLiberte</author>
</authors>
<title>Dan; and the GNU Manual Group</title>
<date>1990</date>
<booktitle>The GNU Emacs Lisp reference manual. Free Software Foundation,</booktitle>
<location>Cambridge, MA.</location>
<marker>Lewis, LaLiberte, 1990</marker>
<rawString>Lewis, Bil; LaLiberte, Dan; and the GNU Manual Group (1990). The GNU Emacs Lisp reference manual. Free Software Foundation, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Magerman</author>
<author>Mitchell P Marcus</author>
</authors>
<title>Parsing a natural language using mutual information statistics.&amp;quot;</title>
<date>1990</date>
<booktitle>In Proceedings of AAAI-90.</booktitle>
<contexts>
<context position="45476" citStr="Magerman and Marcus 1990" startWordPosition="7149" endWordPosition="7152">liminary version of the corpus, we plan to reduce the error rate of the final version of the corpus to approximately 1%. All the skeletally parsed materials have been corrected once, except for the Brown materials, which have been quickly proofread an additional time for gross parsing errors. 5.2 Future Directions A large number of research efforts, both at the University of Pennsylvania and elsewhere, have relied on the output of the Penn Treebank Project to date. A few examples already in print: a number of projects investigating stochastic parsing have used either the POS-tagged materials (Magerman and Marcus 1990; Brill et al. 1990; Brill 1991) or the skeletally parsed corpus (Weischedel et al. 1991; Pereira and Schabes 1992). The POS-tagged corpus has also been used to train a number of different POS taggers including Meteer, Schwartz, and Weischedel (1991), and the skeletally parsed corpus has been used in connection with the development of new methods to exploit intonational cues in disambiguating the parsing of spoken sentences (Veilleux and Ostendorf 1992). The Penn Treebank has been used to bootstrap the development of lexicons for particular applications (Robert Ingria, personal communication) </context>
</contexts>
<marker>Magerman, Marcus, 1990</marker>
<rawString>Magerman, David, and Marcus, Mitchell P. (1990). &amp;quot;Parsing a natural language using mutual information statistics.&amp;quot; In Proceedings of AAAI-90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie Meteer</author>
<author>Richard Schwartz</author>
<author>Ralph Weischedel</author>
</authors>
<title>Studies in part of speech labelling.&amp;quot;</title>
<date>1991</date>
<booktitle>In Proceedings, Fourth DARPA Speech and Natural Language Workshop.</booktitle>
<marker>Meteer, Schwartz, Weischedel, 1991</marker>
<rawString>Meteer, Marie; Schwartz, Richard; and Weischedel, Ralph (1991). &amp;quot;Studies in part of speech labelling.&amp;quot; In Proceedings, Fourth DARPA Speech and Natural Language Workshop. February 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Niv</author>
</authors>
<title>Syntactic disambiguation.&amp;quot;</title>
<date>1991</date>
<journal>In The Penn Review of Linguistics,</journal>
<volume>14</volume>
<pages>120--126</pages>
<contexts>
<context position="46183" citStr="Niv 1991" startWordPosition="7261" endWordPosition="7262">and Schabes 1992). The POS-tagged corpus has also been used to train a number of different POS taggers including Meteer, Schwartz, and Weischedel (1991), and the skeletally parsed corpus has been used in connection with the development of new methods to exploit intonational cues in disambiguating the parsing of spoken sentences (Veilleux and Ostendorf 1992). The Penn Treebank has been used to bootstrap the development of lexicons for particular applications (Robert Ingria, personal communication) and is being used as a source of examples for linguistic theory and psychological modelling (e.g. Niv 1991). To aid in the search for specific examples of grammatical phenomena using the Treebank, Richard Pito has developed tgrep, a tool for very fast context-free pattern matching against the skeletally parsed corpus, which is available through the Linguistic Data Consortium. While the Treebank is being widely used, the annotation scheme employed has a variety of limitations. Many otherwise clear argument/adjunct relations in the corpus are not indicated because of the current Treebank&apos;s essentially context-free representation. For example, there is at present no satisfactory representation for sen</context>
</contexts>
<marker>Niv, 1991</marker>
<rawString>Niv, Michael (1991). &amp;quot;Syntactic disambiguation.&amp;quot; In The Penn Review of Linguistics, 14, 120-126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>Yves Schabes</author>
</authors>
<title>Inside-outside reestimation from partially bracketed corpora.&amp;quot;</title>
<date>1992</date>
<booktitle>In Proceedings, 30th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="45591" citStr="Pereira and Schabes 1992" startWordPosition="7168" endWordPosition="7171">ly 1%. All the skeletally parsed materials have been corrected once, except for the Brown materials, which have been quickly proofread an additional time for gross parsing errors. 5.2 Future Directions A large number of research efforts, both at the University of Pennsylvania and elsewhere, have relied on the output of the Penn Treebank Project to date. A few examples already in print: a number of projects investigating stochastic parsing have used either the POS-tagged materials (Magerman and Marcus 1990; Brill et al. 1990; Brill 1991) or the skeletally parsed corpus (Weischedel et al. 1991; Pereira and Schabes 1992). The POS-tagged corpus has also been used to train a number of different POS taggers including Meteer, Schwartz, and Weischedel (1991), and the skeletally parsed corpus has been used in connection with the development of new methods to exploit intonational cues in disambiguating the parsing of spoken sentences (Veilleux and Ostendorf 1992). The Penn Treebank has been used to bootstrap the development of lexicons for particular applications (Robert Ingria, personal communication) and is being used as a source of examples for linguistic theory and psychological modelling (e.g. Niv 1991). To aid</context>
</contexts>
<marker>Pereira, Schabes, 1992</marker>
<rawString>Pereira, Fernando, and Schabes, Yves (1992). &amp;quot;Inside-outside reestimation from partially bracketed corpora.&amp;quot; In Proceedings, 30th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beatrice Santorini</author>
</authors>
<title>Part-of-speech tagging guidelines for the Penn Treebank Project.&amp;quot;</title>
<date>1990</date>
<tech>Technical report MS-CIS-90-47,</tech>
<institution>Department of Computer and Information Science, University of Pennsylvania.</institution>
<contexts>
<context position="13322" citStr="Santorini (1990)" startWordPosition="2108" endWordPosition="2109">ne. In principle, annotators can tag a word with any number of tags, but in practice, multiple tags are restricted to a small number of recurring two-tag combinations: JJ NN (adjective or noun as prenominal modifier), JJIVBG (adjective or gerund/present participle), JJ IVBN (adjective or past participle), NNIVBG (noun or gerund), and RBIRP (adverb or particle). 2.2 The POS Tagset The Penn Treebank tagset is given in Table 2. It contains 36 POS tags and 12 other tags (for punctuation and currency symbols). A detailed description of the guidelines governing the use of the tagset is available in Santorini (1990).7 2.3 The POS Tagging Process The tagged version of the Penn Treebank corpus is produced in two stages, using a combination of automatic POS assignment and manual correction. 7 In versions of the tagged corpus distributed before November 1992, singular proper nouns, plural proper nouns, and personal pronouns were tagged as &amp;quot;NP,&amp;quot; &amp;quot;NPS,&amp;quot; and &amp;quot;PP,&amp;quot; respectively. The current tags &amp;quot;NNP,&amp;quot; &amp;quot;NNPS,&amp;quot; and &amp;quot;PRP&amp;quot; were introduced in order to avoid confusion with the syntactic tags &amp;quot;NP&amp;quot; (noun phrase) and &amp;quot;PP&amp;quot; (prepositional phrase) (see Table 3). 316 Mitchell P. Marcus et al. Building a Large Annotated Corp</context>
</contexts>
<marker>Santorini, 1990</marker>
<rawString>Santorini, Beatrice (1990). &amp;quot;Part-of-speech tagging guidelines for the Penn Treebank Project.&amp;quot; Technical report MS-CIS-90-47, Department of Computer and Information Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Bracketing guidelines for the Penn Treebank Project.&amp;quot;</title>
<date>1991</date>
<tech>Unpublished manuscript,</tech>
<institution>Department of Computer and Information Science, University of Pennsylvania.</institution>
<contexts>
<context position="25808" citStr="Santorini and Marcinkiewicz (1991)" startWordPosition="4045" endWordPosition="4048">uced by the parser. Using a mouse-based interface, annotators move each unattached chunk of structure under the node to which it should be attached. Notational devices allow annotators to indicate uncertainty concerning constituent labels, and to indicate multiple attachment sites for ambiguous modifiers. The bracketing process is described in more detail in Section 4.3. 4.2 The Syntactic Tagset Table 3 shows the set of syntactic tags and null elements that we use in our skeletal bracketing. More detailed information on the syntactic tagset and guidelines concerning its use are to be found in Santorini and Marcinkiewicz (1991). Although different in detail, our tagset is similar in delicacy to that used by the Lancaster Treebank Project, except that we allow null elements in the syntactic annotation. Because of the need to achieve a fairly high output per hour, it was decided not to require annotators to create distinctions beyond those provided by the parser. Our approach to developing the syntactic tagset was highly pragmatic and strongly influenced by the need to create a large body of annotated material given limited human resources. Despite the skeletal nature of the bracketing, however, it is possible to make</context>
</contexts>
<marker>Santorini, Marcinkiewicz, 1991</marker>
<rawString>Santorini, Beatrice, and Marcinkiewicz, Mary Ann (1991). &amp;quot;Bracketing guidelines for the Penn Treebank Project.&amp;quot; Unpublished manuscript, Department of Computer and Information Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N M Veilleux</author>
<author>Mari Ostendorf</author>
</authors>
<title>Probabilistic parse scoring based on prosodic features.&amp;quot;</title>
<date>1992</date>
<booktitle>In Proceedings, Fifth DARPA Speech and Natural Language Workshop.</booktitle>
<contexts>
<context position="45933" citStr="Veilleux and Ostendorf 1992" startWordPosition="7221" endWordPosition="7224">Project to date. A few examples already in print: a number of projects investigating stochastic parsing have used either the POS-tagged materials (Magerman and Marcus 1990; Brill et al. 1990; Brill 1991) or the skeletally parsed corpus (Weischedel et al. 1991; Pereira and Schabes 1992). The POS-tagged corpus has also been used to train a number of different POS taggers including Meteer, Schwartz, and Weischedel (1991), and the skeletally parsed corpus has been used in connection with the development of new methods to exploit intonational cues in disambiguating the parsing of spoken sentences (Veilleux and Ostendorf 1992). The Penn Treebank has been used to bootstrap the development of lexicons for particular applications (Robert Ingria, personal communication) and is being used as a source of examples for linguistic theory and psychological modelling (e.g. Niv 1991). To aid in the search for specific examples of grammatical phenomena using the Treebank, Richard Pito has developed tgrep, a tool for very fast context-free pattern matching against the skeletally parsed corpus, which is available through the Linguistic Data Consortium. While the Treebank is being widely used, the annotation scheme employed has a </context>
</contexts>
<marker>Veilleux, Ostendorf, 1992</marker>
<rawString>Veilleux, N. M., and Ostendorf, Mari (1992). &amp;quot;Probabilistic parse scoring based on prosodic features.&amp;quot; In Proceedings, Fifth DARPA Speech and Natural Language Workshop. February 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Weischedel</author>
<author>Damaris Ayuso</author>
<author>R Bobrow</author>
<author>Sean Boisen</author>
<author>Robert Ingria</author>
<author>Jeff Palmucci</author>
</authors>
<title>Partial parsing: a report of work in progress.&amp;quot;</title>
<date>1991</date>
<booktitle>In Proceedings, Fourth DARPA Speech and Natural Language Workshop.</booktitle>
<contexts>
<context position="45564" citStr="Weischedel et al. 1991" startWordPosition="7164" endWordPosition="7167">he corpus to approximately 1%. All the skeletally parsed materials have been corrected once, except for the Brown materials, which have been quickly proofread an additional time for gross parsing errors. 5.2 Future Directions A large number of research efforts, both at the University of Pennsylvania and elsewhere, have relied on the output of the Penn Treebank Project to date. A few examples already in print: a number of projects investigating stochastic parsing have used either the POS-tagged materials (Magerman and Marcus 1990; Brill et al. 1990; Brill 1991) or the skeletally parsed corpus (Weischedel et al. 1991; Pereira and Schabes 1992). The POS-tagged corpus has also been used to train a number of different POS taggers including Meteer, Schwartz, and Weischedel (1991), and the skeletally parsed corpus has been used in connection with the development of new methods to exploit intonational cues in disambiguating the parsing of spoken sentences (Veilleux and Ostendorf 1992). The Penn Treebank has been used to bootstrap the development of lexicons for particular applications (Robert Ingria, personal communication) and is being used as a source of examples for linguistic theory and psychological modell</context>
</contexts>
<marker>Weischedel, Ayuso, Bobrow, Boisen, Ingria, Palmucci, 1991</marker>
<rawString>Weischedel, Ralph; Ayuso, Damaris; Bobrow, R.; Boisen, Sean; Ingria, Robert; and Palmucci, Jeff (1991). &amp;quot;Partial parsing: a report of work in progress.&amp;quot; In Proceedings, Fourth DARPA Speech and Natural Language Workshop. February 1991.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>